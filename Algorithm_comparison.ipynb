{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    " \n",
    "# load models\n",
    "mfccmodel = load_model('nn_mfcc_model.h5')\n",
    "melmodel=load_model('nn_mel_model.h5')\n",
    "chromamodel=load_model('nn_chroma_model.h5')\n",
    "tonnetzmodel=load_model('nn_tonnetz_model.h5')\n",
    "contrastmodel=load_model('nn_contrast_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') # default is Kaiser_best\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "     \n",
    "    return mfccsscaled\n",
    "\n",
    "def extract_mel(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') # default is Kaiser_best\n",
    "        mel = np.mean(librosa.feature.melspectrogram(audio, sr=sample_rate).T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "     \n",
    "    return mel\n",
    "\n",
    "def extract_contrast(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') # default is Kaiser_best\n",
    "        stft = np.abs(librosa.stft(audio))\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "     \n",
    "    return contrast\n",
    "\n",
    "def extract_chroma(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') # default is Kaiser_best\n",
    "        stft = np.abs(librosa.stft(audio))\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "     \n",
    "    return chroma\n",
    "\n",
    "def extract_tonnetz(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') # default is Kaiser_best\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(audio),\n",
    "        sr=sample_rate).T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "     \n",
    "    return tonnetz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\librosa\\core\\pitch.py:146: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the full UrbanSound dataset\n",
    "i=0\n",
    "fulldatasetpath = 'G:/urban_dataset'\n",
    "\n",
    "metadata = pd.read_csv(fulldatasetpath + '/metadata/UrbanSound8K.csv')\n",
    "\n",
    "mfccfeatures = []\n",
    "melfeatures=[]\n",
    "contrastfeatures=[]\n",
    "chromafeatures=[]\n",
    "tonnetzfeatures=[]\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "  if i<250: \n",
    "     i+=1\n",
    "     file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    \n",
    "     class_label = row[\"class\"]\n",
    "     mfccdata = extract_mfcc(file_name)\n",
    "     meldata=extract_mel(file_name)\n",
    "     chromadata=extract_chroma(file_name)\n",
    "     contrastdata=extract_contrast(file_name)\n",
    "     tonnetzdata=extract_tonnetz(file_name)\n",
    "    \n",
    "     mfccfeatures.append([mfccdata, class_label])\n",
    "     melfeatures.append([meldata, class_label])\n",
    "     contrastfeatures.append([contrastdata, class_label])\n",
    "     chromafeatures.append([chromadata, class_label])\n",
    "     tonnetzfeatures.append([tonnetzdata, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "mfccdf = pd.DataFrame(mfccfeatures, columns=['feature','class_label'])\n",
    "meldf = pd.DataFrame(melfeatures, columns=['feature','class_label'])\n",
    "contrastdf = pd.DataFrame(contrastfeatures, columns=['feature','class_label'])\n",
    "chromadf = pd.DataFrame(chromafeatures, columns=['feature','class_label'])\n",
    "tonnetzdf = pd.DataFrame(tonnetzfeatures, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "fulldatasetpath = 'G:/urban_dataset'\n",
    "\n",
    "metadata = pd.read_csv(fulldatasetpath + '/metadata/UrbanSound8K.csv')\n",
    "\n",
    "mfccfeatures1 = []\n",
    "melfeatures1=[]\n",
    "contrastfeatures1=[]\n",
    "chromafeatures1=[]\n",
    "tonnetzfeatures1=[]\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "  if i>250 and i<1000: \n",
    "    \n",
    "     file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    \n",
    "     class_label1 = row[\"class\"]\n",
    "     mfccdata1 = extract_mfcc(file_name)\n",
    "     meldata1=extract_mel(file_name)\n",
    "     chromadata1=extract_chroma(file_name)\n",
    "     contrastdata1=extract_contrast(file_name)\n",
    "     tonnetzdata1=extract_tonnetz(file_name)\n",
    "    \n",
    "     mfccfeatures1.append([mfccdata1, class_label1])\n",
    "     melfeatures1.append([meldata1, class_label1])\n",
    "     contrastfeatures1.append([contrastdata1, class_label1])\n",
    "     chromafeatures1.append([chromadata1, class_label1])\n",
    "     tonnetzfeatures1.append([tonnetzdata1, class_label1])\n",
    "  i+=1\n",
    "# Convert into a Panda dataframe \n",
    "mfccdf1 = pd.DataFrame(mfccfeatures1, columns=['feature','class_label'])\n",
    "meldf1 = pd.DataFrame(melfeatures1, columns=['feature','class_label'])\n",
    "contrastdf1 = pd.DataFrame(contrastfeatures1, columns=['feature','class_label'])\n",
    "chromadf1 = pd.DataFrame(chromafeatures1, columns=['feature','class_label'])\n",
    "tonnetzdf1 = pd.DataFrame(tonnetzfeatures1, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250,)\n",
      "250\n",
      "(250, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "mfccX = np.array(mfccdf.feature.tolist())\n",
    "melX = np.array(meldf.feature.tolist())\n",
    "chromaX = np.array(chromadf.feature.tolist())\n",
    "contrastX = np.array(contrastdf.feature.tolist())\n",
    "tonnetzX = np.array(tonnetzdf.feature.tolist())\n",
    "y = np.array(meldf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "print(y.shape)\n",
    "print(len(meldf.class_label.tolist()))\n",
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(749,)\n",
      "749\n",
      "(749, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "mfccX1 = np.array(mfccdf1.feature.tolist())\n",
    "melX1 = np.array(meldf1.feature.tolist())\n",
    "chromaX1 = np.array(chromadf1.feature.tolist())\n",
    "contrastX1 = np.array(contrastdf1.feature.tolist())\n",
    "tonnetzX1 = np.array(tonnetzdf1.feature.tolist())\n",
    "y1 = np.array(meldf1.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy1 = to_categorical(le.fit_transform(y1))\n",
    "print(y1.shape)\n",
    "print(len(meldf1.class_label.tolist()))\n",
    "print(yy1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               16400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 100,250\n",
      "Trainable params: 100,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mfccmodel.summary()\n",
    "results=[]\n",
    "score1 = mfccmodel.evaluate(x=mfccX,y=yy, verbose=0)\n",
    "score2 = melmodel.evaluate(x=melX,y=yy, verbose=0)\n",
    "score3 = contrastmodel.evaluate(x=contrastX,y=yy, verbose=0)\n",
    "score4 = chromamodel.evaluate(x=chromaX,y=yy, verbose=0)\n",
    "score5 = tonnetzmodel.evaluate(x=tonnetzX,y=yy, verbose=0)\n",
    "#results.extend([[score1[1],0],[score2[1],0],[score3[1],0],[score4[1],0],[score5[1],0]])\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               16400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 100,250\n",
      "Trainable params: 100,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[0.936, 0.842], [0.828, 0.731], [0.39200000047683714, 0.3417], [0.28, 0.368], [0.312, 0.1694]]\n"
     ]
    }
   ],
   "source": [
    "mfccmodel.summary()\n",
    "results=[]\n",
    "score11 = mfccmodel.evaluate(x=mfccX1,y=yy1, verbose=0)\n",
    "score21 = melmodel.evaluate(x=melX1,y=yy1, verbose=0)\n",
    "score31 = contrastmodel.evaluate(x=contrastX1,y=yy1, verbose=0)\n",
    "score41 = chromamodel.evaluate(x=chromaX1,y=yy1, verbose=0)\n",
    "score51 = tonnetzmodel.evaluate(x=tonnetzX1,y=yy1, verbose=0)\n",
    "results.extend([[score1[1],0.842],[score2[1],0.7310],[score3[1],0.3417],[score4[1],0.368],[score5[1],0.1694]])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "names=['MFCC','MEL','CONTRAST','CHROMA','TONNETZ']\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
